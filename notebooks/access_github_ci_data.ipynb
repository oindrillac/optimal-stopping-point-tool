{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb38a535-2bcd-46eb-8308-74dee0b62b4a",
   "metadata": {},
   "source": [
    "# Collect data for github action workflow runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7bfd4-0946-4237-93a7-897686ca6a4e",
   "metadata": {},
   "source": [
    "In this notebook, we collect historical test data like the test duration values from running workflows on Github using the GitHub API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b929752-120c-4ac2-b71b-ee59783706df",
   "metadata": {},
   "source": [
    "## Collect data for selected workflow runs of a repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673fb899-9f3c-4fe6-910f-792a41549a75",
   "metadata": {},
   "source": [
    "From historical test workflow runs, want to extract\n",
    "- time durations\n",
    "- workflow run status & conclusion\n",
    "\n",
    "We can get workflow IDs of the test that we are interested in from https://api.github.com/repos/{ORG}/{REPO}/actions/workflows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7fb7a56-46e8-44c3-a6a0-b4bfe23fe80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from subprocess import PIPE\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b754e6-e4ab-4fac-972c-d31289f178f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv(), override=True)\n",
    "TOKEN = os.getenv(\"ACCESS_TOKEN\")\n",
    "ORG = os.getenv(\"ORG\")\n",
    "REPO = os.getenv(\"REPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "842fbe80-3d54-4dfb-83c3-c18c5cdcda89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode can be \"check or \"workflow\" depending on whether you want to collect checks data or workflows data\n",
    "MODE = \"workflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7eb146-b77a-4f3e-be81-906a9cf92885",
   "metadata": {},
   "source": [
    "* Workflows: For example, lets collect data for the test ID 28698040 for the workflow runs in the repository `oss-aspen/8Knot` https://api.github.com/repos/oss-aspen/8Knot/actions/workflows\n",
    "\n",
    "* Checks: Get commits for a repo and get check runs for each commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154cd635-e042-434b-9180-f9408e095497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_numbers(test_id):\n",
    "    \"\"\"\n",
    "    Get the total count of tests.\n",
    "    Find the pages on github-actions.\n",
    "    \"\"\"\n",
    "    command = \"\"\"curl \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/actions/workflows/{}/runs?\"\"\".format(TOKEN, ORG, REPO, test_id)\n",
    "    args = []\n",
    "    args.append(command)\n",
    "    output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "    output = json.loads(output.stdout)\n",
    "    total_count = output['total_count']\n",
    "    page_numbers = int(total_count/30) # by default number of tests on one page is 30\n",
    "    return page_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b74535-4200-49a7-a589-b7adba1bbbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workflow_runs(test_id, page_numbers):\n",
    "    \"\"\"\n",
    "    This function takes test_id and number of pages of workflow runs as input.\n",
    "    Interacts with github api and collects the data for the tests with the specified id.\n",
    "    Outputs the data frame with test data.\n",
    "    \"\"\"\n",
    "    for p in range(1,page_numbers+1):\n",
    "        command = \"\"\"curl \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/actions/workflows/{}/runs?page={}\"\"\".format(TOKEN, ORG, REPO, test_id, p)\n",
    "        args = []\n",
    "        args.append(command)\n",
    "\n",
    "        output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "        output = json.loads(output.stdout)\n",
    "\n",
    "        if p==1:\n",
    "            df = pd.json_normalize(output['workflow_runs'])\n",
    "        else:\n",
    "            df2 = pd.json_normalize(output['workflow_runs'])\n",
    "            df = pd.concat([df, df2], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea54ffd7-9dc3-4331-8f5c-62a3f419130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_check_runs(commits):\n",
    "    \"\"\"\n",
    "    This function takes test_id and number of pages of workflow runs as input.\n",
    "    Interacts with github api and collects the data for the tests with the specified id.\n",
    "    Outputs the data frame with test data.\n",
    "    \"\"\"\n",
    "    appended_data = []\n",
    "    for commit in commits:\n",
    "        command = \"\"\"curl -L \\\n",
    "          -H \"Accept: application/vnd.github+json\" \\\n",
    "          -H \"Authorization: Bearer {}\"\\\n",
    "          -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "          https://api.github.com/repos/{}/{}/commits/{}/check-runs\"\"\".format(TOKEN, ORG, REPO, commit)\n",
    "        args = []\n",
    "        args.append(command)\n",
    "\n",
    "        output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "        output = json.loads(output.stdout)\n",
    "\n",
    "        appended_data.append(pd.json_normalize(output['check_runs']))\n",
    "\n",
    "    df = pd.concat(appended_data, axis=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe31317-ea6b-450c-b818-b0e323d4a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits():\n",
    "    \"This function gets all commit refs for a github repo\"\n",
    "\n",
    "    command =  \"\"\"curl -L \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/commits\"\"\".format(TOKEN, ORG, REPO)\n",
    "    args = []\n",
    "    args.append(command)\n",
    "\n",
    "    output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "    output = json.loads(output.stdout)\n",
    "\n",
    "    df = pd.json_normalize(output)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b21b5a1-60fd-4fd5-9065-dc0bc128b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"check\":\n",
    "    # get checks\n",
    "    df_commits = get_commits()\n",
    "    commit_ids = list(df_commits['sha'])\n",
    "    checks_df = get_check_runs(commit_ids)\n",
    "    test_df = checks_df[['started_at', 'completed_at', 'id', 'status', 'conclusion', 'external_id', 'name']]\n",
    "    test_df = test_df.rename(columns={'external_id': 'test_id', 'id': 'run_id'})\n",
    "    test_df['run_duration'] = test_df.apply(lambda x: (datetime.strptime(x['completed_at'], \"%Y-%m-%dT%H:%M:%SZ\") - \\\n",
    "                                           datetime.strptime(x['started_at'], \"%Y-%m-%dT%H:%M:%SZ\")).total_seconds(), axis = 1)\n",
    "\n",
    "elif MODE == \"workflow\":\n",
    "    # get workflows\n",
    "    test_id = \"28698040\" # Pre-commit test\n",
    "    page_numbers = get_page_numbers(test_id)\n",
    "    workflow_df = get_workflow_runs(test_id, page_numbers)\n",
    "    test_df = workflow_df[['created_at', 'updated_at', 'id', 'status', 'conclusion']]\n",
    "    test_df = test_df.rename(columns={'id': 'run_id'})\n",
    "    test_df['run_duration'] = test_df.apply(lambda x: (datetime.strptime(x['updated_at'], \"%Y-%m-%dT%H:%M:%SZ\") - \\\n",
    "                                           datetime.strptime(x['created_at'], \"%Y-%m-%dT%H:%M:%SZ\")).total_seconds(), axis = 1)\n",
    "    test_df['test_id'] = test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a3a9d1-d34c-49b1-ae7e-5498281af3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>run_id</th>\n",
       "      <th>status</th>\n",
       "      <th>conclusion</th>\n",
       "      <th>run_duration</th>\n",
       "      <th>test_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-18T23:08:38Z</td>\n",
       "      <td>2023-04-18T23:08:59Z</td>\n",
       "      <td>4737765883</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>21.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-18T23:07:18Z</td>\n",
       "      <td>2023-04-18T23:07:49Z</td>\n",
       "      <td>4737757654</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-18T23:07:18Z</td>\n",
       "      <td>2023-04-18T23:07:47Z</td>\n",
       "      <td>4737757619</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-18T23:07:11Z</td>\n",
       "      <td>2023-04-18T23:07:38Z</td>\n",
       "      <td>4737756516</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-18T22:18:27Z</td>\n",
       "      <td>2023-04-18T22:19:00Z</td>\n",
       "      <td>4737464035</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-04-18T22:13:56Z</td>\n",
       "      <td>2023-04-18T22:14:22Z</td>\n",
       "      <td>4737431952</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-04-18T17:59:51Z</td>\n",
       "      <td>2023-04-18T18:00:17Z</td>\n",
       "      <td>4735494421</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-04-17T20:59:45Z</td>\n",
       "      <td>2023-04-17T21:00:08Z</td>\n",
       "      <td>4725766296</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-04-13T23:51:03Z</td>\n",
       "      <td>2023-04-13T23:51:32Z</td>\n",
       "      <td>4694849600</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-04-13T21:48:12Z</td>\n",
       "      <td>2023-04-13T21:48:40Z</td>\n",
       "      <td>4694100853</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28698040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at            updated_at      run_id     status   \n",
       "0  2023-04-18T23:08:38Z  2023-04-18T23:08:59Z  4737765883  completed  \\\n",
       "1  2023-04-18T23:07:18Z  2023-04-18T23:07:49Z  4737757654  completed   \n",
       "2  2023-04-18T23:07:18Z  2023-04-18T23:07:47Z  4737757619  completed   \n",
       "3  2023-04-18T23:07:11Z  2023-04-18T23:07:38Z  4737756516  completed   \n",
       "4  2023-04-18T22:18:27Z  2023-04-18T22:19:00Z  4737464035  completed   \n",
       "5  2023-04-18T22:13:56Z  2023-04-18T22:14:22Z  4737431952  completed   \n",
       "6  2023-04-18T17:59:51Z  2023-04-18T18:00:17Z  4735494421  completed   \n",
       "7  2023-04-17T20:59:45Z  2023-04-17T21:00:08Z  4725766296  completed   \n",
       "8  2023-04-13T23:51:03Z  2023-04-13T23:51:32Z  4694849600  completed   \n",
       "9  2023-04-13T21:48:12Z  2023-04-13T21:48:40Z  4694100853  completed   \n",
       "\n",
       "  conclusion  run_duration   test_id  \n",
       "0    success          21.0  28698040  \n",
       "1    success          31.0  28698040  \n",
       "2    success          29.0  28698040  \n",
       "3    success          27.0  28698040  \n",
       "4    success          33.0  28698040  \n",
       "5    success          26.0  28698040  \n",
       "6    success          26.0  28698040  \n",
       "7    success          23.0  28698040  \n",
       "8    success          29.0  28698040  \n",
       "9    success          28.0  28698040  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b190635-42b8-4011-a244-7dc951375f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "392e9f16-92f5-4ef0-99af-0399765db21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating passing and failing dfs which are neccesary for computing fit distributions\n",
    "passing_df = test_df[test_df['conclusion'] == 'success'] \n",
    "failures_df = test_df[test_df['conclusion'] == 'failure'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9193e440-27a8-4c6f-8a24-23f07e6a2445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b12038cd-03aa-44b6-aa8b-e94ec2184d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failures_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bb5a164-1b39-4c73-b7e1-b324338c85df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test.\n",
    "passing_train, passing_test = train_test_split(passing_df, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47a29a24-0031-4b6b-9df9-a14d42eeb5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "failing_train, failing_test = train_test_split(failures_df, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8249748-1e5e-4022-8e40-8c7860b943d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passing_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1ade87d-091f-4c5d-99c8-62b8490794ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passing_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13d94578-0e8c-4ce0-8cb5-4b87c9da6152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failing_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2a375d6-6271-48db-a532-519665fad2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failing_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11973eff-ca6d-4749-bbfe-ebe17d3b3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_train.to_csv(\"../data/processed/passing_train.csv\")\n",
    "failing_train.to_csv(\"../data/processed/failing_train.csv\")\n",
    "passing_test.to_csv(\"../data/processed/passing_test.csv\")\n",
    "failing_test.to_csv(\"../data/processed/failing_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0eb1d9-abae-4ab9-b470-0f908ef66c57",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we interact with the github api to collect the data for all workflow runs. In future work, we will look into using this data to perform statistical tests using OSP model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
