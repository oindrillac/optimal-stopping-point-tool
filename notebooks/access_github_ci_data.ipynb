{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb38a535-2bcd-46eb-8308-74dee0b62b4a",
   "metadata": {},
   "source": [
    "# Collect data for github action workflow runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7bfd4-0946-4237-93a7-897686ca6a4e",
   "metadata": {},
   "source": [
    "In this notebook, we collect historical test data like the test duration values from running workflows on Github using the GitHub API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b929752-120c-4ac2-b71b-ee59783706df",
   "metadata": {},
   "source": [
    "## Collect data for selected workflow runs of a repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673fb899-9f3c-4fe6-910f-792a41549a75",
   "metadata": {},
   "source": [
    "From historical test workflow runs, want to extract\n",
    "- time durations\n",
    "- workflow run status & conclusion\n",
    "\n",
    "We can get workflow IDs of the test that we are interested in from https://api.github.com/repos/{ORG}/{REPO}/actions/workflows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b7fb7a56-46e8-44c3-a6a0-b4bfe23fe80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from subprocess import PIPE\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c2b754e6-e4ab-4fac-972c-d31289f178f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv(), override=True)\n",
    "TOKEN = os.getenv(\"GITHUB_ACCESS_TOKEN\")\n",
    "ORG = os.getenv(\"ORG\")\n",
    "REPO = os.getenv(\"REPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "842fbe80-3d54-4dfb-83c3-c18c5cdcda89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode can be \"check or \"workflow\" depending on whether you want to collect checks data or workflows data\n",
    "MODE = \"workflow\"\n",
    "# test_id = \"28698040\" # Pre-commit test\n",
    "# test_id = \"37149896\" # File linting\n",
    "# test_id = \"37149895\" # Spell Check\n",
    "# test_id = \"39411153\" #\"Compile all queries using the latest stable CodeQL CLI\"\n",
    "# test_id = \"19425791\" # \"CodeQL tests\"\n",
    "test_id = \"14909022\" # \"CodeQL tests\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7eb146-b77a-4f3e-be81-906a9cf92885",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Workflows: For example, lets collect data for the test ID 28698040 for the workflow runs in the repository `oss-aspen/8Knot` https://api.github.com/repos/oss-aspen/8Knot/actions/workflows\n",
    "\n",
    "* Checks: Get commits for a repo and get check runs for each commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "154cd635-e042-434b-9180-f9408e095497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_numbers(test_id):\n",
    "    \"\"\"\n",
    "    Get the total count of tests.\n",
    "    Find the pages on github-actions.\n",
    "    \"\"\"\n",
    "    command = \"\"\"curl \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/actions/workflows/{}/runs?\"\"\".format(TOKEN, ORG, REPO, test_id)\n",
    "    args = []\n",
    "    args.append(command)\n",
    "    output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "    output = json.loads(output.stdout)\n",
    "    total_count = output['total_count']\n",
    "    page_numbers = int(total_count/30) # by default number of tests on one page is 30\n",
    "    return page_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "f9b74535-4200-49a7-a589-b7adba1bbbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workflow_runs(test_id, page_numbers):\n",
    "    \"\"\"\n",
    "    This function takes test_id and number of pages of workflow runs as input.\n",
    "    Interacts with github api and collects the data for the tests with the specified id.\n",
    "    Outputs the data frame with test data.\n",
    "    \"\"\"\n",
    "    for p in range(1,page_numbers+1):\n",
    "        command = \"\"\"curl \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/actions/workflows/{}/runs?page={}\"\"\".format(TOKEN, ORG, REPO, test_id, p)\n",
    "        args = []\n",
    "        args.append(command)\n",
    "\n",
    "        output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "        output = json.loads(output.stdout)\n",
    "\n",
    "        if p==1:\n",
    "            df = pd.json_normalize(output['workflow_runs'])\n",
    "        else:\n",
    "            df2 = pd.json_normalize(output['workflow_runs'])\n",
    "            df = pd.concat([df, df2], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "ea54ffd7-9dc3-4331-8f5c-62a3f419130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_check_runs(commits):\n",
    "    \"\"\"\n",
    "    This function takes test_id and number of pages of workflow runs as input.\n",
    "    Interacts with github api and collects the data for the tests with the specified id.\n",
    "    Outputs the data frame with test data.\n",
    "    \"\"\"\n",
    "    appended_data = []\n",
    "    for commit in commits:\n",
    "        command = \"\"\"curl -L \\\n",
    "          -H \"Accept: application/vnd.github+json\" \\\n",
    "          -H \"Authorization: Bearer {}\"\\\n",
    "          -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "          https://api.github.com/repos/{}/{}/commits/{}/check-runs\"\"\".format(TOKEN, ORG, REPO, commit)\n",
    "        args = []\n",
    "        args.append(command)\n",
    "\n",
    "        output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "        output = json.loads(output.stdout)\n",
    "\n",
    "        appended_data.append(pd.json_normalize(output['check_runs']))\n",
    "\n",
    "    df = pd.concat(appended_data, axis=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "dfe31317-ea6b-450c-b818-b0e323d4a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits():\n",
    "    \"This function gets all commit refs for a github repo\"\n",
    "\n",
    "    command =  \"\"\"curl -L \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/commits\"\"\".format(TOKEN, ORG, REPO)\n",
    "    args = []\n",
    "    args.append(command)\n",
    "\n",
    "    output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "    output = json.loads(output.stdout)\n",
    "\n",
    "    df = pd.json_normalize(output)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "6b21b5a1-60fd-4fd5-9065-dc0bc128b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"check\":\n",
    "    # get checks\n",
    "    df_commits = get_commits()\n",
    "    commit_ids = list(df_commits['sha'])\n",
    "    checks_df = get_check_runs(commit_ids)\n",
    "    test_df = checks_df[['started_at', 'completed_at', 'id', 'status', 'conclusion', 'external_id', 'name']]\n",
    "    test_df = test_df.rename(columns={'external_id': 'test_id', 'id': 'run_id'})\n",
    "    test_df['run_duration'] = test_df.apply(lambda x: (datetime.strptime(x['completed_at'], \"%Y-%m-%dT%H:%M:%SZ\") - \\\n",
    "                                           datetime.strptime(x['started_at'], \"%Y-%m-%dT%H:%M:%SZ\")).total_seconds(), axis = 1)\n",
    "\n",
    "elif MODE == \"workflow\":\n",
    "    # get workflows\n",
    "    page_numbers = get_page_numbers(test_id)\n",
    "    workflow_df = get_workflow_runs(test_id, page_numbers)\n",
    "    test_df = workflow_df[['created_at', 'updated_at', 'id', 'status', 'conclusion']]\n",
    "    test_df = test_df.rename(columns={'id': 'run_id'})\n",
    "    test_df['run_duration'] = test_df.apply(lambda x: (datetime.strptime(x['updated_at'], \"%Y-%m-%dT%H:%M:%SZ\") - \\\n",
    "                                           datetime.strptime(x['created_at'], \"%Y-%m-%dT%H:%M:%SZ\")).total_seconds(), axis = 1)\n",
    "    test_df['test_id'] = test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "24a3a9d1-d34c-49b1-ae7e-5498281af3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>run_id</th>\n",
       "      <th>status</th>\n",
       "      <th>conclusion</th>\n",
       "      <th>run_duration</th>\n",
       "      <th>test_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-06T21:09:43Z</td>\n",
       "      <td>2023-04-06T21:09:56Z</td>\n",
       "      <td>4633082469</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-06T21:03:11Z</td>\n",
       "      <td>2023-04-06T21:03:26Z</td>\n",
       "      <td>4633026850</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-06T21:01:59Z</td>\n",
       "      <td>2023-04-06T21:02:13Z</td>\n",
       "      <td>4633016889</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-06T20:55:05Z</td>\n",
       "      <td>2023-04-06T20:55:18Z</td>\n",
       "      <td>4632971052</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-06T17:12:11Z</td>\n",
       "      <td>2023-04-06T17:12:25Z</td>\n",
       "      <td>4631351495</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-04-06T17:08:50Z</td>\n",
       "      <td>2023-04-06T17:09:06Z</td>\n",
       "      <td>4631323889</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-04-06T16:11:26Z</td>\n",
       "      <td>2023-04-06T16:11:41Z</td>\n",
       "      <td>4630875820</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-04-06T15:46:28Z</td>\n",
       "      <td>2023-04-06T15:46:43Z</td>\n",
       "      <td>4630668380</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-04-06T15:42:12Z</td>\n",
       "      <td>2023-04-06T15:42:27Z</td>\n",
       "      <td>4630633820</td>\n",
       "      <td>completed</td>\n",
       "      <td>success</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-04-06T15:40:36Z</td>\n",
       "      <td>2023-04-06T15:40:50Z</td>\n",
       "      <td>4630621799</td>\n",
       "      <td>completed</td>\n",
       "      <td>failure</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14909022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at            updated_at      run_id     status  \\\n",
       "0  2023-04-06T21:09:43Z  2023-04-06T21:09:56Z  4633082469  completed   \n",
       "1  2023-04-06T21:03:11Z  2023-04-06T21:03:26Z  4633026850  completed   \n",
       "2  2023-04-06T21:01:59Z  2023-04-06T21:02:13Z  4633016889  completed   \n",
       "3  2023-04-06T20:55:05Z  2023-04-06T20:55:18Z  4632971052  completed   \n",
       "4  2023-04-06T17:12:11Z  2023-04-06T17:12:25Z  4631351495  completed   \n",
       "5  2023-04-06T17:08:50Z  2023-04-06T17:09:06Z  4631323889  completed   \n",
       "6  2023-04-06T16:11:26Z  2023-04-06T16:11:41Z  4630875820  completed   \n",
       "7  2023-04-06T15:46:28Z  2023-04-06T15:46:43Z  4630668380  completed   \n",
       "8  2023-04-06T15:42:12Z  2023-04-06T15:42:27Z  4630633820  completed   \n",
       "9  2023-04-06T15:40:36Z  2023-04-06T15:40:50Z  4630621799  completed   \n",
       "\n",
       "  conclusion  run_duration   test_id  \n",
       "0    success          13.0  14909022  \n",
       "1    success          15.0  14909022  \n",
       "2    success          14.0  14909022  \n",
       "3    success          13.0  14909022  \n",
       "4    success          14.0  14909022  \n",
       "5    success          16.0  14909022  \n",
       "6    success          15.0  14909022  \n",
       "7    success          15.0  14909022  \n",
       "8    success          15.0  14909022  \n",
       "9    failure          14.0  14909022  "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "1b190635-42b8-4011-a244-7dc951375f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 7)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "392e9f16-92f5-4ef0-99af-0399765db21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating passing and failing dfs which are neccesary for computing fit distributions\n",
    "passing_df = test_df[test_df['conclusion'] == 'success'] \n",
    "failures_df = test_df[test_df['conclusion'] == 'failure'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "9193e440-27a8-4c6f-8a24-23f07e6a2445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849, 7)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "b12038cd-03aa-44b6-aa8b-e94ec2184d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failures_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "9bb5a164-1b39-4c73-b7e1-b324338c85df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test.\n",
    "passing_train, passing_test = train_test_split(passing_df, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "47a29a24-0031-4b6b-9df9-a14d42eeb5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "failing_train, failing_test = train_test_split(failures_df, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "c8249748-1e5e-4022-8e40-8c7860b943d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(679, 7)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passing_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "e1ade87d-091f-4c5d-99c8-62b8490794ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 7)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passing_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "13d94578-0e8c-4ce0-8cb5-4b87c9da6152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 7)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failing_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "c2a375d6-6271-48db-a532-519665fad2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 7)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failing_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "11973eff-ca6d-4749-bbfe-ebe17d3b3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "passing_train.to_csv(\"../data/processed/{}passing_train.csv\".format(test_id))\n",
    "failing_train.to_csv(\"../data/processed/{}failing_train.csv\".format(test_id))\n",
    "passing_test.to_csv(\"../data/processed/{}passing_test.csv\".format(test_id))\n",
    "failing_test.to_csv(\"../data/processed/{}failing_test.csv\".format(test_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0eb1d9-abae-4ab9-b470-0f908ef66c57",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we interact with the github api to collect the data for all workflow runs. In future work, we will look into using this data to perform statistical tests using OSP model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
