{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb38a535-2bcd-46eb-8308-74dee0b62b4a",
   "metadata": {},
   "source": [
    "# Collect data for github action workflow runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7bfd4-0946-4237-93a7-897686ca6a4e",
   "metadata": {},
   "source": [
    "In this notebook, we collect historical test data like the test duration values from running workflows on Github using the GitHub API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b929752-120c-4ac2-b71b-ee59783706df",
   "metadata": {},
   "source": [
    "## Collect data for selected workflow runs of a repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673fb899-9f3c-4fe6-910f-792a41549a75",
   "metadata": {},
   "source": [
    "From historical test workflow runs, want to extract\n",
    "- time durations\n",
    "- workflow run status & conclusion\n",
    "\n",
    "We can get workflow IDs of the test that we are interested in from https://api.github.com/repos/{ORG}/{REPO}/actions/workflows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7fb7a56-46e8-44c3-a6a0-b4bfe23fe80d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:59:59.371700Z",
     "iopub.status.busy": "2023-04-19T18:59:59.371444Z",
     "iopub.status.idle": "2023-04-19T18:59:59.959780Z",
     "shell.execute_reply": "2023-04-19T18:59:59.959139Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from subprocess import PIPE\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b754e6-e4ab-4fac-972c-d31289f178f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:59:59.963709Z",
     "iopub.status.busy": "2023-04-19T18:59:59.963094Z",
     "iopub.status.idle": "2023-04-19T18:59:59.968014Z",
     "shell.execute_reply": "2023-04-19T18:59:59.967428Z"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv(), override=True)\n",
    "TOKEN = os.getenv(\"ACCESS_TOKEN\")\n",
    "ORG = os.getenv(\"ORG\")\n",
    "REPO = os.getenv(\"REPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "842fbe80-3d54-4dfb-83c3-c18c5cdcda89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:59:59.970897Z",
     "iopub.status.busy": "2023-04-19T18:59:59.970682Z",
     "iopub.status.idle": "2023-04-19T18:59:59.973421Z",
     "shell.execute_reply": "2023-04-19T18:59:59.972823Z"
    }
   },
   "outputs": [],
   "source": [
    "# mode can be \"check or \"workflow\" depending on whether you want to collect checks data or workflows data\n",
    "MODE = \"workflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7eb146-b77a-4f3e-be81-906a9cf92885",
   "metadata": {},
   "source": [
    "* Workflows: For example, lets collect data for the test ID 28698040 for the workflow runs in the repository `oss-aspen/8Knot` https://api.github.com/repos/oss-aspen/8Knot/actions/workflows\n",
    "\n",
    "* Checks: Get commits for a repo and get check runs for each commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154cd635-e042-434b-9180-f9408e095497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:59:59.976710Z",
     "iopub.status.busy": "2023-04-19T18:59:59.976508Z",
     "iopub.status.idle": "2023-04-19T18:59:59.980811Z",
     "shell.execute_reply": "2023-04-19T18:59:59.980194Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_page_numbers(test_id):\n",
    "    \"\"\"\n",
    "    Get the total count of tests.\n",
    "    Find the pages on github-actions.\n",
    "    \"\"\"\n",
    "    command = \"\"\"curl \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/actions/workflows/{}/runs?\"\"\".format(TOKEN, ORG, REPO, test_id)\n",
    "    args = []\n",
    "    args.append(command)\n",
    "    output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "    output = json.loads(output.stdout)\n",
    "    print(command)\n",
    "#     total_count = output['total_count']\n",
    "#     page_numbers = int(total_count/30) # by default number of tests on one page is 30\n",
    "#     return page_numbers\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b74535-4200-49a7-a589-b7adba1bbbb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:59:59.983395Z",
     "iopub.status.busy": "2023-04-19T18:59:59.983188Z",
     "iopub.status.idle": "2023-04-19T18:59:59.988263Z",
     "shell.execute_reply": "2023-04-19T18:59:59.987654Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_workflow_runs(test_id, page_numbers):\n",
    "    \"\"\"\n",
    "    This function takes test_id and number of pages of workflow runs as input.\n",
    "    Interacts with github api and collects the data for the tests with the specified id.\n",
    "    Outputs the data frame with test data.\n",
    "    \"\"\"\n",
    "    for p in range(1,page_numbers+1):\n",
    "        command = \"\"\"curl \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/actions/workflows/{}/runs?page={}\"\"\".format(TOKEN, ORG, REPO, test_id, p)\n",
    "        args = []\n",
    "        args.append(command)\n",
    "\n",
    "        output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "        output = json.loads(output.stdout)\n",
    "\n",
    "        if p==1:\n",
    "            df = pd.json_normalize(output['workflow_runs'])\n",
    "        else:\n",
    "            df2 = pd.json_normalize(output['workflow_runs'])\n",
    "            df = pd.concat([df, df2], axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea54ffd7-9dc3-4331-8f5c-62a3f419130c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:59:59.991050Z",
     "iopub.status.busy": "2023-04-19T18:59:59.990841Z",
     "iopub.status.idle": "2023-04-19T18:59:59.995273Z",
     "shell.execute_reply": "2023-04-19T18:59:59.994667Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_check_runs(commits):\n",
    "    \"\"\"\n",
    "    This function takes test_id and number of pages of workflow runs as input.\n",
    "    Interacts with github api and collects the data for the tests with the specified id.\n",
    "    Outputs the data frame with test data.\n",
    "    \"\"\"\n",
    "    appended_data = []\n",
    "    for commit in commits:\n",
    "        command = \"\"\"curl -L \\\n",
    "          -H \"Accept: application/vnd.github+json\" \\\n",
    "          -H \"Authorization: Bearer {}\"\\\n",
    "          -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "          https://api.github.com/repos/{}/{}/commits/{}/check-runs\"\"\".format(TOKEN, ORG, REPO, commit)\n",
    "        args = []\n",
    "        args.append(command)\n",
    "\n",
    "        output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "        output = json.loads(output.stdout)\n",
    "\n",
    "        appended_data.append(pd.json_normalize(output['check_runs']))\n",
    "\n",
    "    df = pd.concat(appended_data, axis=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe31317-ea6b-450c-b818-b0e323d4a3bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:59:59.997998Z",
     "iopub.status.busy": "2023-04-19T18:59:59.997782Z",
     "iopub.status.idle": "2023-04-19T19:00:00.001651Z",
     "shell.execute_reply": "2023-04-19T19:00:00.001060Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_commits():\n",
    "    \"This function gets all commit refs for a github repo\"\n",
    "\n",
    "    command =  \"\"\"curl -L \\\n",
    "      -H \"Accept: application/vnd.github+json\" \\\n",
    "      -H \"Authorization: Bearer {}\"\\\n",
    "      -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "      https://api.github.com/repos/{}/{}/commits\"\"\".format(TOKEN, ORG, REPO)\n",
    "    args = []\n",
    "    args.append(command)\n",
    "\n",
    "    output = subprocess.run(args, shell=True, check=True, stdout=PIPE, stderr=PIPE)\n",
    "    output = json.loads(output.stdout)\n",
    "\n",
    "    df = pd.json_normalize(output)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b21b5a1-60fd-4fd5-9065-dc0bc128b596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:00:00.004415Z",
     "iopub.status.busy": "2023-04-19T19:00:00.004204Z",
     "iopub.status.idle": "2023-04-19T19:00:00.086625Z",
     "shell.execute_reply": "2023-04-19T19:00:00.085680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl       -H \"Accept: application/vnd.github+json\"       -H \"Authorization: Bearer None\"      -H \"X-GitHub-Api-Version: 2022-11-28\"       https://api.github.com/repos/None/None/actions/workflows/28698040/runs?\n",
      "curl       -H \"Accept: application/vnd.github+json\"       -H \"Authorization: Bearer None\"      -H \"X-GitHub-Api-Version: 2022-11-28\"       https://api.github.com/repos/None/None/actions/workflows/28698040/runs?\n"
     ]
    }
   ],
   "source": [
    "if MODE == \"check\":\n",
    "    # get checks\n",
    "    df_commits = get_commits()\n",
    "    commit_ids = list(df_commits['sha'])\n",
    "    checks_df = get_check_runs(commit_ids)\n",
    "    test_df = checks_df[['started_at', 'completed_at', 'id', 'status', 'conclusion', 'external_id', 'name']]\n",
    "    test_df = test_df.rename(columns={'external_id': 'test_id', 'id': 'run_id'})\n",
    "    test_df['run_duration'] = test_df.apply(lambda x: (datetime.strptime(x['completed_at'], \"%Y-%m-%dT%H:%M:%SZ\") - \\\n",
    "                                           datetime.strptime(x['started_at'], \"%Y-%m-%dT%H:%M:%SZ\")).total_seconds(), axis = 1)\n",
    "\n",
    "elif MODE == \"workflow\":\n",
    "    # get workflows\n",
    "    test_id = \"28698040\" # Pre-commit test\n",
    "    page_numbers = get_page_numbers(test_id)\n",
    "    print(page_numbers)\n",
    "#     workflow_df = get_workflow_runs(test_id, page_numbers)\n",
    "#     test_df = workflow_df[['created_at', 'updated_at', 'id', 'status', 'conclusion']]\n",
    "#     test_df = test_df.rename(columns={'id': 'run_id'})\n",
    "#     test_df['run_duration'] = test_df.apply(lambda x: (datetime.strptime(x['updated_at'], \"%Y-%m-%dT%H:%M:%SZ\") - \\\n",
    "#                                            datetime.strptime(x['created_at'], \"%Y-%m-%dT%H:%M:%SZ\")).total_seconds(), axis = 1)\n",
    "#     test_df['test_id'] = test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a3a9d1-d34c-49b1-ae7e-5498281af3e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:00:00.090533Z",
     "iopub.status.busy": "2023-04-19T19:00:00.089797Z",
     "iopub.status.idle": "2023-04-19T19:00:00.094220Z",
     "shell.execute_reply": "2023-04-19T19:00:00.093043Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b190635-42b8-4011-a244-7dc951375f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:00:00.097226Z",
     "iopub.status.busy": "2023-04-19T19:00:00.096776Z",
     "iopub.status.idle": "2023-04-19T19:00:00.099697Z",
     "shell.execute_reply": "2023-04-19T19:00:00.099085Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "392e9f16-92f5-4ef0-99af-0399765db21e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:00:00.102785Z",
     "iopub.status.busy": "2023-04-19T19:00:00.102216Z",
     "iopub.status.idle": "2023-04-19T19:00:00.105309Z",
     "shell.execute_reply": "2023-04-19T19:00:00.104687Z"
    }
   },
   "outputs": [],
   "source": [
    "# # generating passing and failing dfs which are neccesary for computing fit distributions\n",
    "# passing_df = test_df[test_df['conclusion'] == 'success'] \n",
    "# failures_df = test_df[test_df['conclusion'] == 'failure'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9193e440-27a8-4c6f-8a24-23f07e6a2445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:00:00.107920Z",
     "iopub.status.busy": "2023-04-19T19:00:00.107707Z",
     "iopub.status.idle": "2023-04-19T19:00:00.110520Z",
     "shell.execute_reply": "2023-04-19T19:00:00.109897Z"
    }
   },
   "outputs": [],
   "source": [
    "# passing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b12038cd-03aa-44b6-aa8b-e94ec2184d09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:00:00.113572Z",
     "iopub.status.busy": "2023-04-19T19:00:00.113210Z",
     "iopub.status.idle": "2023-04-19T19:00:00.116372Z",
     "shell.execute_reply": "2023-04-19T19:00:00.115569Z"
    }
   },
   "outputs": [],
   "source": [
    "# failures_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bb5a164-1b39-4c73-b7e1-b324338c85df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:00:00.119652Z",
     "iopub.status.busy": "2023-04-19T19:00:00.119122Z",
     "iopub.status.idle": "2023-04-19T19:00:00.122103Z",
     "shell.execute_reply": "2023-04-19T19:00:00.121455Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test.\n",
    "# passing_train, passing_test = train_test_split(passing_df, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47a29a24-0031-4b6b-9df9-a14d42eeb5f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:00:00.124701Z",
     "iopub.status.busy": "2023-04-19T19:00:00.124483Z",
     "iopub.status.idle": "2023-04-19T19:00:00.127418Z",
     "shell.execute_reply": "2023-04-19T19:00:00.126776Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "# failing_train, failing_test = train_test_split(failures_df, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8249748-1e5e-4022-8e40-8c7860b943d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:00:00.130013Z",
     "iopub.status.busy": "2023-04-19T19:00:00.129671Z",
     "iopub.status.idle": "2023-04-19T19:00:00.132582Z",
     "shell.execute_reply": "2023-04-19T19:00:00.131987Z"
    }
   },
   "outputs": [],
   "source": [
    "# passing_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1ade87d-091f-4c5d-99c8-62b8490794ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:00:00.135174Z",
     "iopub.status.busy": "2023-04-19T19:00:00.134965Z",
     "iopub.status.idle": "2023-04-19T19:00:00.137641Z",
     "shell.execute_reply": "2023-04-19T19:00:00.137002Z"
    }
   },
   "outputs": [],
   "source": [
    "# passing_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13d94578-0e8c-4ce0-8cb5-4b87c9da6152",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:00:00.140169Z",
     "iopub.status.busy": "2023-04-19T19:00:00.139962Z",
     "iopub.status.idle": "2023-04-19T19:00:00.142585Z",
     "shell.execute_reply": "2023-04-19T19:00:00.141994Z"
    }
   },
   "outputs": [],
   "source": [
    "# failing_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2a375d6-6271-48db-a532-519665fad2b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:00:00.145095Z",
     "iopub.status.busy": "2023-04-19T19:00:00.144886Z",
     "iopub.status.idle": "2023-04-19T19:00:00.147485Z",
     "shell.execute_reply": "2023-04-19T19:00:00.146882Z"
    }
   },
   "outputs": [],
   "source": [
    "# failing_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11973eff-ca6d-4749-bbfe-ebe17d3b3ec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:00:00.150499Z",
     "iopub.status.busy": "2023-04-19T19:00:00.149959Z",
     "iopub.status.idle": "2023-04-19T19:00:00.152836Z",
     "shell.execute_reply": "2023-04-19T19:00:00.152242Z"
    }
   },
   "outputs": [],
   "source": [
    "# passing_train.to_csv(\"../data/processed/passing_train.csv\")\n",
    "# failing_train.to_csv(\"../data/processed/failing_train.csv\")\n",
    "# passing_test.to_csv(\"../data/processed/passing_test.csv\")\n",
    "# failing_test.to_csv(\"../data/processed/failing_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0eb1d9-abae-4ab9-b470-0f908ef66c57",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we interact with the github api to collect the data for all workflow runs. In future work, we will look into using this data to perform statistical tests using OSP model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
